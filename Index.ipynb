{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"zLCTeDm-jLfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704583929059,"user_tz":300,"elapsed":4592,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"33cdba46-170f-4d1d-d563-4ae1e07131f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1704583929062,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"AnaSX0XUjLfV","outputId":"15cfa9d2-6820-4d37-c557-fb9c1046f771"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification\n","common\t     dataloading  Index.ipynb  preprocess\t     run.yaml\n","config.yaml  experiments  index.py     project-structure.md  transforms\n","data\t     Index_bc.py  models       README.md\t     visualization\n"]}],"source":["# move into project directory\n","repo_name = \"crop-damage-classification\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1704583929062,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"qVSyI39BjLfW","outputId":"5b027d08-6328-49e1-8449-c73ece01d305"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"markdown","metadata":{"id":"uZ3v5itpj3ae"},"source":["# Following cells are for downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17078,"status":"ok","timestamp":1704583946114,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"1Ox_E5YpjLfW","outputId":"858df7d7-0500-41b0-e522-4de830002434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.14)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.14 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.14)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.14->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.14->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.14->boto3) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# comment if not required\n","!pip install boto3\n","!pip install tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5549,"status":"ok","timestamp":1704583951602,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"kwOcWXgAjLfW"},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from transforms.transforms import ToTensor, Resize, CenterCrop\n","from dataloading.dataset import CropDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config\n","from models.resnet18 import Resnet18\n","from experiments.experiments import Experiment\n","from visualization.visualization import Visualization\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":54,"status":"ok","timestamp":1704583951606,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"i_Jc81A_kF4o"},"outputs":[],"source":["import boto3\n","from pathlib import Path\n","from botocore import UNSIGNED\n","from botocore.client import Config\n","from tqdm.notebook import tqdm\n","\n","def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n","    file_names = []\n","    folders = []\n","\n","    default_kwargs = {\n","        \"Bucket\": bucket_name,\n","        \"Prefix\": prefix\n","    }\n","    next_token = \"\"\n","\n","    while next_token is not None:\n","        updated_kwargs = default_kwargs.copy()\n","        if next_token != \"\":\n","            updated_kwargs[\"ContinuationToken\"] = next_token\n","\n","        response = s3_client.list_objects_v2(**updated_kwargs)\n","        contents = response.get(\"Contents\")\n","\n","        for result in contents:\n","            key = result.get(\"Key\")\n","            if key[-1] == \"/\":\n","                folders.append(key)\n","            else:\n","                file_names.append(key)\n","\n","        next_token = response.get(\"NextContinuationToken\")\n","\n","    return file_names, folders\n","\n","def download_files(s3_client, bucket_name, local_path, file_names, folders):\n","    local_path = Path(local_path)\n","\n","    for folder in tqdm(folders):\n","        folder_path = Path.joinpath(local_path, folder)\n","\t\t\t\t# Create all folders in the path\n","        folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for file_name in tqdm(file_names):\n","        file_path = Path.joinpath(local_path, file_name)\n","\t\t\t\t# Create folder for parent directory\n","        file_path.parent.mkdir(parents=True, exist_ok=True)\n","        s3_client.download_file(\n","            bucket_name,\n","            file_name,\n","            str(file_path)\n","        )\n","\n","data_path = 'data/input/images'\n","if not(os.path.exists(os.path.join(os.getcwd(), data_path))):\n","    client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n","    file_names, folders = get_file_folders(client, 'cgiar-crop-damage-classification-challenge')\n","    download_files(\n","        client,\n","        'cgiar-crop-damage-classification-challenge',\n","        \"/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input\",\n","        file_names,\n","        folders\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1704583951607,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"b5bdgR1sjLfX","outputId":"94de9f99-b06f-49ad-8249-35f0fba6ce1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 256, 'crop_dim': 224}, 'train': {'shuffle_data': True, 'batch_size': 128, 'val_split_method': 'k-fold', 'k': 5, 'val_percentage': 20, 'loss': 'cross-entropy', 'batch_interval': 512, 'epoch_interval': 1, 'num_epochs': 10}, 'model': {'name': 'resnet18', 'optimizer': 'Adam', 'lr': 0.001, 'weight_decay': 1e-05, 'amsgrad': False, 'momentum': 0.9}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1704583951883,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"swtjFj_LjLfX","outputId":"5ad076af-617b-4f33-f080-69cf0ee0ce07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config parameters\n","\n","{'X_key': 'image', 'data_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data', 'img_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input/images', 'root_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification', 'use_gpu': True, 'y_key': 'label'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1704583951886,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"GEnkN2-_jLfY"},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qS5oBZb9jLfY","executionInfo":{"status":"ok","timestamp":1704583951898,"user_tz":300,"elapsed":58,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["#preprocess data or load preprocessed data\n","\n","#build label dict\n","label_dict = {\n","    'DR': 0,\n","    'G': 1,\n","    'ND': 2,\n","    'WD': 3,\n","    'other': 4\n","}"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gu_4BlM-UCkr","executionInfo":{"status":"ok","timestamp":1704583951899,"user_tz":300,"elapsed":50,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"62decfe3-acf2-4710-b9b8-0f30c8fec4ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full train dataset length: 26068\n","Test dataset length: 8663\n","Subset train dataset length: 1303 \n","\n"]}],"source":["#save X_key and y_key\n","save2config('X_key', 'image')\n","save2config('y_key', 'label')\n","\n","#transform data\n","data_transforms = transforms.Compose([ToTensor(), Resize(exp_params['transform']['resize_dim']), CenterCrop(exp_params['transform']['crop_dim'])])\n","\n","#convert to dataset\n","ftr_dataset = CropDataset('input/Train.csv', label_dict, transforms=data_transforms)\n","test_dataset = CropDataset('input/Test.csv', label_dict, transforms=data_transforms)\n","smlen = int(0.05 * len(ftr_dataset))\n","smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","print('Full train dataset length:', len(ftr_dataset))\n","print('Test dataset length:', len(test_dataset))\n","print('Subset train dataset length:', smlen, '\\n')\n","\n"]},{"cell_type":"code","source":["#model import\n","\n","if exp_params['model']['name'] == 'resnet18':\n","    model = Resnet18(5, False)\n","else:\n","    raise SystemExit(\"Error: Invalid model name passed! Check run.yaml\")\n"],"metadata":{"id":"yv38w4M3VS7b","executionInfo":{"status":"ok","timestamp":1704583951900,"user_tz":300,"elapsed":46,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-YdanntUCks","outputId":"fac1fc8f-f706-47ea-af3d-2c910bc463ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running split 0\n","\tRunning Epoch 0\n","\t\tRunning through training dataset\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]}],"source":["#running experiment on small subset of the dataset\n","\n","exp = Experiment(model, smftr_dataset)\n","model_info = exp.train()\n","print(\"\\nModel validation results\")\n","\n","#visualization results\n","vis = Visualization(model_info)\n","vis.get_results()"]},{"cell_type":"code","source":["#model training on full dataset\n","'''\n","exp = Experiment(model, ftr_dataset)\n","model_info = exp.train()\n","print(\"\\nModel validation results\")\n","\n","#visualization results\n","vis = Visualization(model_info)\n","vis.get_results()\n","'''"],"metadata":{"id":"LeBlN4k7VZFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HHfDthUUCks"},"outputs":[],"source":["#model testing\n","'''\n","print(\"Testing Best Model\")\n","exp.test(model_info[\"best_model\"], test_dataset)\n","print(\"\\nTesting Last Model\")\n","exp.test(model_info[\"last_model\"], test_dataset)\n","'''"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}