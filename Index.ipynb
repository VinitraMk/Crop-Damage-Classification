{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4143,"status":"ok","timestamp":1705402539015,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"zLCTeDm-jLfS","outputId":"a8ad2299-9dfe-4557-f014-728378dd09fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1705402539016,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"AnaSX0XUjLfV","outputId":"9adb883a-dadb-416f-c66a-4789efd7937e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification\n","common\t\t    data\t Index_bc.py  models\t  preprocess_input.py\trun.yaml\n","config.yaml\t    dataloading  Index.ipynb  output\t  project-structure.md\ttransforms\n","corrupt_files.json  experiments  index.py     preprocess  README.md\t\tvisualization\n"]}],"source":["# move into project directory\n","repo_name = \"crop-damage-classification\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1705402539017,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"qVSyI39BjLfW","outputId":"ef9eecc4-68f4-4f57-88b0-c8310f9462cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (2.1.2)\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torch) (3.1.3)\n","Collecting fsspec (from torch)\n","  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from torchvision) (1.24.3)\n","Collecting requests (from torchvision)\n","  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m390.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n","\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n","  Downloading https://download.pytorch.org/whl/Pillow-9.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n","Collecting charset-normalizer<3,>=2 (from requests->torchvision)\n","  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n","Collecting idna<4,>=2.5 (from requests->torchvision)\n","  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m489.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->torchvision)\n","  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m886.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: urllib3, pillow, idna, fsspec, charset-normalizer, requests, torchvision, torchaudio\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","matplotlib 3.8.0 requires pyparsing>=2.3.1, which is not installed.\n","botocore 1.34.12 requires jmespath<2.0.0,>=0.7.1, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed charset-normalizer-2.1.1 fsspec-2023.4.0 idna-3.4 pillow-9.3.0 requests-2.28.1 torchaudio-2.1.2+cu118 torchvision-0.16.2+cu118 urllib3-1.26.13\n","Requirement already satisfied: matplotlib in /home/mikasaackerman/.local/lib/python3.10/site-packages (3.8.0)\n","Requirement already satisfied: numpy==1.24.3 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (1.24.3)\n","Collecting pandas\n","  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: pyyaml in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (6.0.1)\n","Requirement already satisfied: opencv-python in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (4.8.1.78)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/mikasaackerman/.local/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /home/mikasaackerman/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/mikasaackerman/.local/lib/python3.10/site-packages (from matplotlib) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/mikasaackerman/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n","Collecting pyparsing>=2.3.1 (from matplotlib)\n","  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/mikasaackerman/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n","Collecting pytz>=2020.1 (from pandas)\n","  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.1 (from pandas)\n","  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: six>=1.5 in /home/mikasaackerman/anaconda3/envs/mlprojects/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m291.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pytz, tzdata, pyparsing, pandas\n","Successfully installed pandas-2.1.4 pyparsing-3.1.1 pytz-2023.3.post1 tzdata-2023.4\n"]}],"source":["# set up environment\n","# comment if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy==1.24.3 pandas pyyaml opencv-python\n","'''"]},{"cell_type":"markdown","metadata":{"id":"uZ3v5itpj3ae"},"source":["# Following cells are for downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34772,"status":"ok","timestamp":1705402573775,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"1Ox_E5YpjLfW","outputId":"87f25d11-5b65-4214-ebe9-7623cdde61dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting boto3\n","  Downloading boto3-1.34.19-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m810.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.35.0,>=1.34.19 (from boto3)\n","  Downloading botocore-1.34.19-py3-none-any.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n","  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.19->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.19->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.19->boto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.34.19 botocore-1.34.19 jmespath-1.0.1 s3transfer-0.10.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# comment if not required\n","!pip install boto3\n","!pip install tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":10397,"status":"ok","timestamp":1705402584148,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"kwOcWXgAjLfW"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torchvision'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# setup some imports\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#custom imports\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensor, Resize, CenterCrop\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloading\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CropDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_exp_params, init_config, get_config, save2config, get_modelinfo, get_saved_model, read_json, insert_index_2csv\n","File \u001b[0;32m~/projects/ml-projects/crop-damage-classification/transforms/transforms.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, utils\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"]}],"source":["# setup some imports\n","#custom imports\n","from transforms.transforms import ToTensor, Resize, CenterCrop\n","from dataloading.dataset import CropDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_modelinfo, get_saved_model, read_json, insert_index_2csv\n","from models.resnet18 import Resnet18\n","from models.custom_models import get_model\n","from experiments.experiments import Experiment\n","from visualization.visualization import Visualization\n","from experiments.test_model import ModelTester\n","from preprocess.preprocessor import Preprocessor\n","from tqdm import tqdm\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":554,"status":"ok","timestamp":1705402584677,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"i_Jc81A_kF4o"},"outputs":[],"source":["import boto3\n","from pathlib import Path\n","from botocore import UNSIGNED\n","from botocore.client import Config\n","from tqdm.notebook import tqdm\n","\n","def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n","    file_names = []\n","    folders = []\n","\n","    default_kwargs = {\n","        \"Bucket\": bucket_name,\n","        \"Prefix\": prefix\n","    }\n","    next_token = \"\"\n","\n","    while next_token is not None:\n","        updated_kwargs = default_kwargs.copy()\n","        if next_token != \"\":\n","            updated_kwargs[\"ContinuationToken\"] = next_token\n","\n","        response = s3_client.list_objects_v2(**updated_kwargs)\n","        contents = response.get(\"Contents\")\n","\n","        for result in contents:\n","            key = result.get(\"Key\")\n","            if key[-1] == \"/\":\n","                folders.append(key)\n","            else:\n","                file_names.append(key)\n","\n","        next_token = response.get(\"NextContinuationToken\")\n","\n","    return file_names, folders\n","\n","def download_files(s3_client, bucket_name, local_path, file_names, folders):\n","    local_path = Path(local_path)\n","\n","    for folder in tqdm(folders):\n","        folder_path = Path.joinpath(local_path, folder)\n","\t\t\t\t# Create all folders in the path\n","        folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for file_name in tqdm(file_names):\n","        file_path = Path.joinpath(local_path, file_name)\n","\t\t\t\t# Create folder for parent directory\n","        file_path.parent.mkdir(parents=True, exist_ok=True)\n","        s3_client.download_file(\n","            bucket_name,\n","            file_name,\n","            str(file_path)\n","        )\n","\n","data_path = 'data/input/images'\n","if not(os.path.exists(os.path.join(os.getcwd(), data_path))):\n","    client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n","    file_names, folders = get_file_folders(client, 'cgiar-crop-damage-classification-challenge')\n","    download_files(\n","        client,\n","        'cgiar-crop-damage-classification-challenge',\n","        \"/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input\",\n","        file_names,\n","        folders\n","    )"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1705402584679,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"swtjFj_LjLfX","outputId":"62077eac-915a-4822-e216-a5e9793c5453"},"outputs":[{"name":"stdout","output_type":"stream","text":["Config parameters\n","\n","{'X_key': 'image', 'data_dir': '/home/mikasaackerman/projects/ml-projects/crop-damage-classification/data', 'device': 'cpu', 'img_dir': '/home/mikasaackerman/projects/ml-projects/crop-damage-classification/data/input/images', 'output_dir': '/home/mikasaackerman/projects/ml-projects/crop-damage-classification/output', 'root_dir': '/home/mikasaackerman/projects/ml-projects/crop-damage-classification', 'use_gpu': False, 'y_key': 'label'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1705402584902,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"I8-C7DyPZfie","outputId":"6d617922-1f0d-4a16-8603-73df13bf7c4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["scanning files for corrupt images\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/34731 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 34731/34731 [00:14<00:00, 2368.38it/s]\n"]}],"source":["#clean up invalid images\n","'''\n","from PIL import Image, UnidentifiedImageError\n","import json\n","import pandas as pd\n","\n","image_files = os.listdir(os.path.join(config['root_dir'],'data/input/images'))\n","corrupt_files = []\n","print('scanning files for corrupt images\\n\\n')\n","for img_file in tqdm(image_files):\n","    try:\n","        img = Image.open(os.path.join(config['img_dir'], img_file))\n","    except UnidentifiedImageError as e:\n","        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\n","            os.remove(os.path.join(config[\"data_dir\"], img_file))\n","        corrupt_files.append(img_file)\n","#corrupt_files = ['c3092a5186771280a99200624c4f67e33fde95ca.jpg']\n","data = { \"data\": corrupt_files }\n","with open('corrupt_files.json', 'w') as fp:\n","    json.dump(data, fp)\n","\n","train_path = os.path.join(config['data_dir'], 'input/Train.csv')\n","train_df = pd.read_csv(train_path)\n","error_rows = train_df.loc[train_df['filename'].isin(corrupt_files)].index.tolist()\n","train_df = train_df.drop(labels = error_rows)\n","train_df.to_csv(train_path, index = False)\n","'''"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1705402584904,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"GHtbUZ58jID3"},"outputs":[],"source":["# insert index column to label csvs\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Train.csv'))\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Test.csv'))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1705402585228,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"b5bdgR1sjLfX","outputId":"ad2b08b3-4fd8-4e81-b6a3-3de9817d5b42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 256, 'crop_dim': 224}, 'train': {'shuffle_data': False, 'batch_size': 128, 'val_split_method': 'k-fold', 'k': 3, 'val_percentage': 20, 'loss': 'cross-entropy', 'epoch_interval': 1, 'num_epochs': 5}, 'model': {'name': 'resnet18', 'optimizer': 'Adam', 'lr': 0.001, 'weight_decay': 1e-05, 'amsgrad': False, 'momentum': 0.9}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1705402585229,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"GEnkN2-_jLfY"},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1705402585229,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"qS5oBZb9jLfY"},"outputs":[],"source":["#preprocess data or load preprocessed data\n","\n","#build label dict\n","label_dict = {\n","    'DR': 0,\n","    'G': 1,\n","    'ND': 2,\n","    'WD': 3,\n","    'other': 4\n","}\n","\n","class_dict = {\n","    0: 'DR',\n","    1: 'G',\n","    2: 'ND',\n","    3: 'WD',\n","    4: 'other'\n","}"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1705402585475,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"Gu_4BlM-UCkr","outputId":"593dcce3-0150-453b-a818-ca9f92df563f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset length: 26068\n","Test dataset length: 8663\n","Subset train dataset length: 260\n","Subset test dataset length: 86 \n","\n"]}],"source":["#save X_key and y_key\n","save2config('X_key', 'image')\n","save2config('y_key', 'label')\n","\n","#transform data\n","data_transforms = [ToTensor(), Resize(exp_params['transform']['resize_dim']), CenterCrop(exp_params['transform']['crop_dim'])]\n","\n","#convert to dataset\n","ftr_dataset = CropDataset('input/Train.csv', label_dict, False)\n","test_dataset = CropDataset('input/Test.csv', label_dict, True)\n","smlen = int(0.01 * len(ftr_dataset))\n","smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","smtelen = int(0.01 * len(test_dataset))\n","smfte_dataset = torch.utils.data.Subset(test_dataset, list(range(smtelen)))\n","print('Full train dataset length:', len(ftr_dataset))\n","print('Test dataset length:', len(test_dataset))\n","print('Subset train dataset length:', smlen)\n","print('Subset test dataset length:', smtelen, '\\n')\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1705402585478,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"9oYnMlWAtKHc","outputId":"5caea029-f609-414b-8e94-402e73069fda"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nprint(\"Getting metrics for small data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","print(\"Getting metrics for small data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1705402585481,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"i-YdanntUCks","outputId":"4495e224-ed9f-46b4-ef6a-e7c31433ffbe"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n#running experiment on small subset of the dataset\\nexp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\\nmodel_history = exp.train()\\n\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","#running experiment on small subset of the dataset\n","exp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKroKRypQgkc","outputId":"b9eaa2e5-2cde-4931-e714-51602127d3ae"},"outputs":[],"source":["print(\"Getting metrics for data\")\n","preop = Preprocessor()\n","print(np.__version__)\n","all_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\n","print(all_folds_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeBlN4k7VZFY"},"outputs":[],"source":["#model training on full dataset\n","exp = Experiment(exp_params['model']['name'], ftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuSnMkZmnDrG"},"outputs":[],"source":["# get best model\n","model = get_model(exp_params[\"model\"][\"name\"])\n","model = get_saved_model(model, '')\n","model_info = get_modelinfo('')\n","best_fold = model_info['results']['fold']\n","metric_path = os.path.join(config[\"root_dir\"], \"models/checkpoints/all_folds_metrics.json\")\n","all_folds_metrics = read_json(metric_path)\n","print('All folds metrics')\n","print(all_folds_metrics)\n","\n","print(\"\\nModel validation results\")\n","print(model_info['results']['trlosshistory'])\n","#visualization results\n","vis = Visualization(model_info, model_history)\n","vis.get_results()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvqYKcgPnm9r"},"outputs":[],"source":["'''\n","#model testing on small test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, smfte_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJFUzpYxF-1A"},"outputs":[],"source":["#model testing on test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, test_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
