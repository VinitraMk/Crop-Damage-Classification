{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4143,"status":"ok","timestamp":1705402539015,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"zLCTeDm-jLfS","outputId":"a8ad2299-9dfe-4557-f014-728378dd09fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1705402539016,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"AnaSX0XUjLfV","outputId":"9adb883a-dadb-416f-c66a-4789efd7937e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification\n","common\t\t    data\t Index_bc.py  models\t  preprocess_input.py\trun.yaml\n","config.yaml\t    dataloading  Index.ipynb  output\t  project-structure.md\ttransforms\n","corrupt_files.json  experiments  index.py     preprocess  README.md\t\tvisualization\n"]}],"source":["# move into project directory\n","repo_name = \"crop-damage-classification\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1705402539017,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"qVSyI39BjLfW","outputId":"ef9eecc4-68f4-4f57-88b0-c8310f9462cb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# set up environment\n","# comment if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"markdown","metadata":{"id":"uZ3v5itpj3ae"},"source":["# Following cells are for downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34772,"status":"ok","timestamp":1705402573775,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"1Ox_E5YpjLfW","outputId":"87f25d11-5b65-4214-ebe9-7623cdde61dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting boto3\n","  Downloading boto3-1.34.19-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m810.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore\u003c1.35.0,\u003e=1.34.19 (from boto3)\n","  Downloading botocore-1.34.19-py3-none-any.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath\u003c2.0.0,\u003e=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer\u003c0.11.0,\u003e=0.10.0 (from boto3)\n","  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil\u003c3.0.0,\u003e=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore\u003c1.35.0,\u003e=1.34.19-\u003eboto3) (2.8.2)\n","Requirement already satisfied: urllib3\u003c2.1,\u003e=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore\u003c1.35.0,\u003e=1.34.19-\u003eboto3) (2.0.7)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003c3.0.0,\u003e=2.1-\u003ebotocore\u003c1.35.0,\u003e=1.34.19-\u003eboto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.34.19 botocore-1.34.19 jmespath-1.0.1 s3transfer-0.10.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# comment if not required\n","!pip install boto3\n","!pip install tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10397,"status":"ok","timestamp":1705402584148,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"kwOcWXgAjLfW"},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from transforms.transforms import ToTensor, Resize, CenterCrop\n","from dataloading.dataset import CropDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_modelinfo, get_saved_model, read_json, insert_index_2csv\n","from models.resnet18 import Resnet18\n","from models.custom_models import get_model\n","from experiments.experiments import Experiment\n","from visualization.visualization import Visualization\n","from experiments.test_model import ModelTester\n","from preprocess.preprocessor import Preprocessor\n","from tqdm import tqdm\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":554,"status":"ok","timestamp":1705402584677,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"i_Jc81A_kF4o"},"outputs":[],"source":["import boto3\n","from pathlib import Path\n","from botocore import UNSIGNED\n","from botocore.client import Config\n","from tqdm.notebook import tqdm\n","\n","def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n","    file_names = []\n","    folders = []\n","\n","    default_kwargs = {\n","        \"Bucket\": bucket_name,\n","        \"Prefix\": prefix\n","    }\n","    next_token = \"\"\n","\n","    while next_token is not None:\n","        updated_kwargs = default_kwargs.copy()\n","        if next_token != \"\":\n","            updated_kwargs[\"ContinuationToken\"] = next_token\n","\n","        response = s3_client.list_objects_v2(**updated_kwargs)\n","        contents = response.get(\"Contents\")\n","\n","        for result in contents:\n","            key = result.get(\"Key\")\n","            if key[-1] == \"/\":\n","                folders.append(key)\n","            else:\n","                file_names.append(key)\n","\n","        next_token = response.get(\"NextContinuationToken\")\n","\n","    return file_names, folders\n","\n","def download_files(s3_client, bucket_name, local_path, file_names, folders):\n","    local_path = Path(local_path)\n","\n","    for folder in tqdm(folders):\n","        folder_path = Path.joinpath(local_path, folder)\n","\t\t\t\t# Create all folders in the path\n","        folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for file_name in tqdm(file_names):\n","        file_path = Path.joinpath(local_path, file_name)\n","\t\t\t\t# Create folder for parent directory\n","        file_path.parent.mkdir(parents=True, exist_ok=True)\n","        s3_client.download_file(\n","            bucket_name,\n","            file_name,\n","            str(file_path)\n","        )\n","\n","data_path = 'data/input/images'\n","if not(os.path.exists(os.path.join(os.getcwd(), data_path))):\n","    client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n","    file_names, folders = get_file_folders(client, 'cgiar-crop-damage-classification-challenge')\n","    download_files(\n","        client,\n","        'cgiar-crop-damage-classification-challenge',\n","        \"/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input\",\n","        file_names,\n","        folders\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1705402584679,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"swtjFj_LjLfX","outputId":"62077eac-915a-4822-e216-a5e9793c5453"},"outputs":[{"name":"stdout","output_type":"stream","text":["Config parameters\n","\n","{'X_key': 'image', 'data_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data', 'device': 'cpu', 'img_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input/images', 'output_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification', 'use_gpu': False, 'y_key': 'label'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1705402584902,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"I8-C7DyPZfie","outputId":"6d617922-1f0d-4a16-8603-73df13bf7c4d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfrom PIL import Image, UnidentifiedImageError\\nimport json\\nimport pandas as pd\\n\\nimage_files = os.listdir(os.path.join(config[\\'root_dir\\'],\\'data/input/images\\'))\\ncorrupt_files = []\\nprint(\\'scanning files for corrupt images\\n\\n\\')\\nfor img_file in tqdm(image_files):\\n    try:\\n        img = Image.open(os.path.join(config[\\'img_dir\\'], img_file))\\n    except UnidentifiedImageError as e:\\n        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\\n            os.remove(os.path.join(config[\"data_dir\"], img_file))\\n        corrupt_files.append(img_file)\\n#corrupt_files = [\\'c3092a5186771280a99200624c4f67e33fde95ca.jpg\\']\\ndata = { \"data\": corrupt_files }\\nwith open(\\'corrupt_files.json\\', \\'w\\') as fp:\\n    json.dump(data, fp)\\n\\ntrain_path = os.path.join(config[\\'data_dir\\'], \\'input/Train.csv\\')\\ntrain_df = pd.read_csv(train_path)\\nerror_rows = train_df.loc[train_df[\\'filename\\'].isin(corrupt_files)].index.tolist()\\ntrain_df = train_df.drop(labels = error_rows)\\ntrain_df.to_csv(train_path, index = False)\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#clean up invalid images\n","\n","'''\n","from PIL import Image, UnidentifiedImageError\n","import json\n","import pandas as pd\n","\n","image_files = os.listdir(os.path.join(config['root_dir'],'data/input/images'))\n","corrupt_files = []\n","print('scanning files for corrupt images\\n\\n')\n","for img_file in tqdm(image_files):\n","    try:\n","        img = Image.open(os.path.join(config['img_dir'], img_file))\n","    except UnidentifiedImageError as e:\n","        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\n","            os.remove(os.path.join(config[\"data_dir\"], img_file))\n","        corrupt_files.append(img_file)\n","#corrupt_files = ['c3092a5186771280a99200624c4f67e33fde95ca.jpg']\n","data = { \"data\": corrupt_files }\n","with open('corrupt_files.json', 'w') as fp:\n","    json.dump(data, fp)\n","\n","train_path = os.path.join(config['data_dir'], 'input/Train.csv')\n","train_df = pd.read_csv(train_path)\n","error_rows = train_df.loc[train_df['filename'].isin(corrupt_files)].index.tolist()\n","train_df = train_df.drop(labels = error_rows)\n","train_df.to_csv(train_path, index = False)\n","'''"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1705402584904,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"GHtbUZ58jID3"},"outputs":[],"source":["# insert index column to label csvs\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Train.csv'))\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Test.csv'))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1705402585228,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"b5bdgR1sjLfX","outputId":"ad2b08b3-4fd8-4e81-b6a3-3de9817d5b42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 256, 'crop_dim': 224}, 'train': {'shuffle_data': False, 'batch_size': 128, 'val_split_method': 'k-fold', 'k': 3, 'val_percentage': 20, 'loss': 'cross-entropy', 'epoch_interval': 1, 'num_epochs': 5}, 'model': {'name': 'resnet18', 'optimizer': 'Adam', 'lr': 0.001, 'weight_decay': 1e-05, 'amsgrad': False, 'momentum': 0.9}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1705402585229,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"GEnkN2-_jLfY"},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1705402585229,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"qS5oBZb9jLfY"},"outputs":[],"source":["#preprocess data or load preprocessed data\n","\n","#build label dict\n","label_dict = {\n","    'DR': 0,\n","    'G': 1,\n","    'ND': 2,\n","    'WD': 3,\n","    'other': 4\n","}\n","\n","class_dict = {\n","    0: 'DR',\n","    1: 'G',\n","    2: 'ND',\n","    3: 'WD',\n","    4: 'other'\n","}"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1705402585475,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"Gu_4BlM-UCkr","outputId":"593dcce3-0150-453b-a818-ca9f92df563f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset length: 26067\n","Test dataset length: 8663\n","Subset train dataset length: 260\n","Subset test dataset length: 86 \n","\n"]}],"source":["#save X_key and y_key\n","save2config('X_key', 'image')\n","save2config('y_key', 'label')\n","\n","#transform data\n","data_transforms = [ToTensor(), Resize(exp_params['transform']['resize_dim']), CenterCrop(exp_params['transform']['crop_dim'])]\n","\n","#convert to dataset\n","ftr_dataset = CropDataset('input/Train.csv', label_dict, False)\n","test_dataset = CropDataset('input/Test.csv', label_dict, True)\n","smlen = int(0.01 * len(ftr_dataset))\n","smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","smtelen = int(0.01 * len(test_dataset))\n","smfte_dataset = torch.utils.data.Subset(test_dataset, list(range(smtelen)))\n","print('Full train dataset length:', len(ftr_dataset))\n","print('Test dataset length:', len(test_dataset))\n","print('Subset train dataset length:', smlen)\n","print('Subset test dataset length:', smtelen, '\\n')\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1705402585478,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"9oYnMlWAtKHc","outputId":"5caea029-f609-414b-8e94-402e73069fda"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nprint(\"Getting metrics for small data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","print(\"Getting metrics for small data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1705402585481,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"i-YdanntUCks","outputId":"4495e224-ed9f-46b4-ef6a-e7c31433ffbe"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n#running experiment on small subset of the dataset\\nexp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\\nmodel_history = exp.train()\\n\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","#running experiment on small subset of the dataset\n","exp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()\n","'''"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8192707,"status":"ok","timestamp":1705410778150,"user":{"displayName":"Vinitra Mk","userId":"02676117449369578011"},"user_tz":300},"id":"NKroKRypQgkc","outputId":"b9eaa2e5-2cde-4931-e714-51602127d3ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting metrics for data\n","\tCalculating metric for split 0 starting with 0, ending with 8689\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification/common/utils.py:248: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  batchlist = list(map(np.array, zip(*batch)))\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\t\tGetting metrics for batch 0\n","\t\tGetting metrics for batch 1\n","\t\tGetting metrics for batch 2\n","\t\tGetting metrics for batch 3\n","\t\tGetting metrics for batch 4\n","\t\tGetting metrics for batch 5\n","\t\tGetting metrics for batch 6\n","\t\tGetting metrics for batch 7\n","\t\tGetting metrics for batch 8\n","\t\tGetting metrics for batch 9\n","\t\tGetting metrics for batch 10\n","\t\tGetting metrics for batch 11\n","\t\tGetting metrics for batch 12\n","\t\tGetting metrics for batch 13\n","\t\tGetting metrics for batch 14\n","\t\tGetting metrics for batch 15\n","\t\tGetting metrics for batch 16\n","\t\tGetting metrics for batch 17\n","\t\tGetting metrics for batch 18\n","\t\tGetting metrics for batch 19\n","\t\tGetting metrics for batch 20\n","\t\tGetting metrics for batch 21\n","\t\tGetting metrics for batch 22\n","\t\tGetting metrics for batch 23\n","\t\tGetting metrics for batch 24\n","\t\tGetting metrics for batch 25\n","\t\tGetting metrics for batch 26\n","\t\tGetting metrics for batch 27\n","\t\tGetting metrics for batch 28\n","\t\tGetting metrics for batch 29\n","\t\tGetting metrics for batch 30\n","\t\tGetting metrics for batch 31\n","\t\tGetting metrics for batch 32\n","\t\tGetting metrics for batch 33\n","\t\tGetting metrics for batch 34\n","\t\tGetting metrics for batch 35\n","\t\tGetting metrics for batch 36\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification/common/utils.py:248: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  batchlist = list(map(np.array, zip(*batch)))\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\t\tGetting metrics for batch 37\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","/content/drive/MyDrive/Personal-Projects/crop-damage-classification/common/utils.py:248: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  batchlist = list(map(np.array, zip(*batch)))\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\t\tGetting metrics for batch 38\n","\t\tGetting metrics for batch 39\n","\t\tGetting metrics for batch 40\n","\t\tGetting metrics for batch 41\n","\t\tGetting metrics for batch 42\n","\t\tGetting metrics for batch 43\n","\t\tGetting metrics for batch 44\n","\t\tGetting metrics for batch 45\n","\t\tGetting metrics for batch 46\n","\t\tGetting metrics for batch 47\n","\t\tGetting metrics for batch 48\n","\t\tGetting metrics for batch 49\n","\t\tGetting metrics for batch 50\n","\t\tGetting metrics for batch 51\n","\t\tGetting metrics for batch 52\n","\t\tGetting metrics for batch 53\n","\t\tGetting metrics for batch 54\n","\t\tGetting metrics for batch 55\n","\t\tGetting metrics for batch 56\n","\t\tGetting metrics for batch 57\n","\t\tGetting metrics for batch 58\n","\t\tGetting metrics for batch 59\n","\t\tGetting metrics for batch 60\n","\t\tGetting metrics for batch 61\n","\t\tGetting metrics for batch 62\n","\t\tGetting metrics for batch 63\n","\t\tGetting metrics for batch 64\n","\t\tGetting metrics for batch 65\n","\t\tGetting metrics for batch 66\n","\t\tGetting metrics for batch 67\n","\t\tGetting metrics for batch 68\n","\t\tGetting metrics for batch 69\n","\t\tGetting metrics for batch 70\n","\t\tGetting metrics for batch 71\n","\t\tGetting metrics for batch 72\n","\t\tGetting metrics for batch 73\n","\t\tGetting metrics for batch 74\n","\t\tGetting metrics for batch 75\n","\t\tGetting metrics for batch 76\n","\t\tGetting metrics for batch 77\n","\t\tGetting metrics for batch 78\n","\t\tGetting metrics for batch 79\n","\t\tGetting metrics for batch 80\n","\t\tGetting metrics for batch 81\n","\t\tGetting metrics for batch 82\n","\t\tGetting metrics for batch 83\n","\t\tGetting metrics for batch 84\n","\t\tGetting metrics for batch 85\n","\t\tGetting metrics for batch 86\n","\t\tGetting metrics for batch 87\n","\t\tGetting metrics for batch 88\n","\t\tGetting metrics for batch 89\n","\t\tGetting metrics for batch 90\n","\t\tGetting metrics for batch 91\n","\t\tGetting metrics for batch 92\n","\t\tGetting metrics for batch 93\n","\t\tGetting metrics for batch 94\n","\t\tGetting metrics for batch 95\n","\t\tGetting metrics for batch 96\n","\t\tGetting metrics for batch 97\n","\t\tGetting metrics for batch 98\n","\t\tGetting metrics for batch 99\n","\t\tGetting metrics for batch 100\n","\t\tGetting metrics for batch 101\n","\t\tGetting metrics for batch 102\n","\t\tGetting metrics for batch 103\n","\t\tGetting metrics for batch 104\n","\t\tGetting metrics for batch 105\n","\t\tGetting metrics for batch 106\n","\t\tGetting metrics for batch 107\n","\t\tGetting metrics for batch 108\n","\t\tGetting metrics for batch 109\n","\t\tGetting metrics for batch 110\n","\t\tGetting metrics for batch 111\n","\t\tGetting metrics for batch 112\n","\t\tGetting metrics for batch 113\n","\t\tGetting metrics for batch 114\n","\t\tGetting metrics for batch 115\n","\t\tGetting metrics for batch 116\n","\t\tGetting metrics for batch 117\n","\t\tGetting metrics for batch 118\n","\t\tGetting metrics for batch 119\n","\t\tGetting metrics for batch 120\n","\t\tGetting metrics for batch 121\n","\t\tGetting metrics for batch 122\n","\t\tGetting metrics for batch 123\n","\t\tGetting metrics for batch 124\n","\t\tGetting metrics for batch 125\n","\t\tGetting metrics for batch 126\n","\t\tGetting metrics for batch 127\n","\t\tGetting metrics for batch 128\n","\t\tGetting metrics for batch 129\n","\t\tGetting metrics for batch 130\n","\t\tGetting metrics for batch 131\n","\t\tGetting metrics for batch 132\n","\t\tGetting metrics for batch 133\n","\t\tGetting metrics for batch 134\n","\t\tGetting metrics for batch 135\n","\tSaved metrics of fold 0\n","\n","\tCalculating metric for split 1 starting with 8689, ending with 17378\n","\t\tGetting metrics for batch 0\n","\t\tGetting metrics for batch 1\n","\t\tGetting metrics for batch 2\n","\t\tGetting metrics for batch 3\n","\t\tGetting metrics for batch 4\n","\t\tGetting metrics for batch 5\n","\t\tGetting metrics for batch 6\n","\t\tGetting metrics for batch 7\n","\t\tGetting metrics for batch 8\n","\t\tGetting metrics for batch 9\n","\t\tGetting metrics for batch 10\n","\t\tGetting metrics for batch 11\n","\t\tGetting metrics for batch 12\n","\t\tGetting metrics for batch 13\n","\t\tGetting metrics for batch 14\n","\t\tGetting metrics for batch 15\n","\t\tGetting metrics for batch 16\n","\t\tGetting metrics for batch 17\n","\t\tGetting metrics for batch 18\n","\t\tGetting metrics for batch 19\n","\t\tGetting metrics for batch 20\n","\t\tGetting metrics for batch 21\n","\t\tGetting metrics for batch 22\n","\t\tGetting metrics for batch 23\n","\t\tGetting metrics for batch 24\n","\t\tGetting metrics for batch 25\n","\t\tGetting metrics for batch 26\n","\t\tGetting metrics for batch 27\n","\t\tGetting metrics for batch 28\n","\t\tGetting metrics for batch 29\n","\t\tGetting metrics for batch 30\n","\t\tGetting metrics for batch 31\n","\t\tGetting metrics for batch 32\n","\t\tGetting metrics for batch 33\n","\t\tGetting metrics for batch 34\n","\t\tGetting metrics for batch 35\n","\t\tGetting metrics for batch 36\n","\t\tGetting metrics for batch 37\n","\t\tGetting metrics for batch 38\n","\t\tGetting metrics for batch 39\n","\t\tGetting metrics for batch 40\n","\t\tGetting metrics for batch 41\n","\t\tGetting metrics for batch 42\n","\t\tGetting metrics for batch 43\n","\t\tGetting metrics for batch 44\n","\t\tGetting metrics for batch 45\n","\t\tGetting metrics for batch 46\n","\t\tGetting metrics for batch 47\n","\t\tGetting metrics for batch 48\n","\t\tGetting metrics for batch 49\n","\t\tGetting metrics for batch 50\n","\t\tGetting metrics for batch 51\n","\t\tGetting metrics for batch 52\n","\t\tGetting metrics for batch 53\n","\t\tGetting metrics for batch 54\n","\t\tGetting metrics for batch 55\n","\t\tGetting metrics for batch 56\n","\t\tGetting metrics for batch 57\n","\t\tGetting metrics for batch 58\n","\t\tGetting metrics for batch 59\n","\t\tGetting metrics for batch 60\n","\t\tGetting metrics for batch 61\n","\t\tGetting metrics for batch 62\n","\t\tGetting metrics for batch 63\n","\t\tGetting metrics for batch 64\n","\t\tGetting metrics for batch 65\n","\t\tGetting metrics for batch 66\n","\t\tGetting metrics for batch 67\n","\t\tGetting metrics for batch 68\n","\t\tGetting metrics for batch 69\n","\t\tGetting metrics for batch 70\n","\t\tGetting metrics for batch 71\n","\t\tGetting metrics for batch 72\n","\t\tGetting metrics for batch 73\n","\t\tGetting metrics for batch 74\n","\t\tGetting metrics for batch 75\n","\t\tGetting metrics for batch 76\n","\t\tGetting metrics for batch 77\n","\t\tGetting metrics for batch 78\n","\t\tGetting metrics for batch 79\n","\t\tGetting metrics for batch 80\n","\t\tGetting metrics for batch 81\n","\t\tGetting metrics for batch 82\n","\t\tGetting metrics for batch 83\n","\t\tGetting metrics for batch 84\n","\t\tGetting metrics for batch 85\n","\t\tGetting metrics for batch 86\n","\t\tGetting metrics for batch 87\n","\t\tGetting metrics for batch 88\n","\t\tGetting metrics for batch 89\n","\t\tGetting metrics for batch 90\n","\t\tGetting metrics for batch 91\n","\t\tGetting metrics for batch 92\n","\t\tGetting metrics for batch 93\n","\t\tGetting metrics for batch 94\n","\t\tGetting metrics for batch 95\n","\t\tGetting metrics for batch 96\n","\t\tGetting metrics for batch 97\n","\t\tGetting metrics for batch 98\n","\t\tGetting metrics for batch 99\n","\t\tGetting metrics for batch 100\n","\t\tGetting metrics for batch 101\n","\t\tGetting metrics for batch 102\n","\t\tGetting metrics for batch 103\n","\t\tGetting metrics for batch 104\n","\t\tGetting metrics for batch 105\n","\t\tGetting metrics for batch 106\n","\t\tGetting metrics for batch 107\n","\t\tGetting metrics for batch 108\n","\t\tGetting metrics for batch 109\n","\t\tGetting metrics for batch 110\n","\t\tGetting metrics for batch 111\n","\t\tGetting metrics for batch 112\n","\t\tGetting metrics for batch 113\n","\t\tGetting metrics for batch 114\n","\t\tGetting metrics for batch 115\n","\t\tGetting metrics for batch 116\n","\t\tGetting metrics for batch 117\n","\t\tGetting metrics for batch 118\n","\t\tGetting metrics for batch 119\n","\t\tGetting metrics for batch 120\n","\t\tGetting metrics for batch 121\n","\t\tGetting metrics for batch 122\n","\t\tGetting metrics for batch 123\n","\t\tGetting metrics for batch 124\n","\t\tGetting metrics for batch 125\n","\t\tGetting metrics for batch 126\n","\t\tGetting metrics for batch 127\n","\t\tGetting metrics for batch 128\n","\t\tGetting metrics for batch 129\n","\t\tGetting metrics for batch 130\n","\t\tGetting metrics for batch 131\n","\t\tGetting metrics for batch 132\n","\t\tGetting metrics for batch 133\n","\t\tGetting metrics for batch 134\n","\t\tGetting metrics for batch 135\n","\tSaved metrics of fold 1\n","\n","\tCalculating metric for split 2 starting with 17378, ending with 26067\n","\t\tGetting metrics for batch 0\n","\t\tGetting metrics for batch 1\n","\t\tGetting metrics for batch 2\n","\t\tGetting metrics for batch 3\n","\t\tGetting metrics for batch 4\n","\t\tGetting metrics for batch 5\n","\t\tGetting metrics for batch 6\n","\t\tGetting metrics for batch 7\n","\t\tGetting metrics for batch 8\n","\t\tGetting metrics for batch 9\n","\t\tGetting metrics for batch 10\n","\t\tGetting metrics for batch 11\n","\t\tGetting metrics for batch 12\n","\t\tGetting metrics for batch 13\n","\t\tGetting metrics for batch 14\n","\t\tGetting metrics for batch 15\n","\t\tGetting metrics for batch 16\n","\t\tGetting metrics for batch 17\n","\t\tGetting metrics for batch 18\n","\t\tGetting metrics for batch 19\n","\t\tGetting metrics for batch 20\n","\t\tGetting metrics for batch 21\n","\t\tGetting metrics for batch 22\n","\t\tGetting metrics for batch 23\n","\t\tGetting metrics for batch 24\n","\t\tGetting metrics for batch 25\n","\t\tGetting metrics for batch 26\n","\t\tGetting metrics for batch 27\n","\t\tGetting metrics for batch 28\n","\t\tGetting metrics for batch 29\n","\t\tGetting metrics for batch 30\n","\t\tGetting metrics for batch 31\n","\t\tGetting metrics for batch 32\n","\t\tGetting metrics for batch 33\n","\t\tGetting metrics for batch 34\n","\t\tGetting metrics for batch 35\n","\t\tGetting metrics for batch 36\n","\t\tGetting metrics for batch 37\n","\t\tGetting metrics for batch 38\n","\t\tGetting metrics for batch 39\n","\t\tGetting metrics for batch 40\n","\t\tGetting metrics for batch 41\n","\t\tGetting metrics for batch 42\n","\t\tGetting metrics for batch 43\n","\t\tGetting metrics for batch 44\n","\t\tGetting metrics for batch 45\n","\t\tGetting metrics for batch 46\n","\t\tGetting metrics for batch 47\n","\t\tGetting metrics for batch 48\n","\t\tGetting metrics for batch 49\n","\t\tGetting metrics for batch 50\n","\t\tGetting metrics for batch 51\n","\t\tGetting metrics for batch 52\n","\t\tGetting metrics for batch 53\n","\t\tGetting metrics for batch 54\n","\t\tGetting metrics for batch 55\n","\t\tGetting metrics for batch 56\n","\t\tGetting metrics for batch 57\n","\t\tGetting metrics for batch 58\n","\t\tGetting metrics for batch 59\n","\t\tGetting metrics for batch 60\n","\t\tGetting metrics for batch 61\n","\t\tGetting metrics for batch 62\n","\t\tGetting metrics for batch 63\n","\t\tGetting metrics for batch 64\n","\t\tGetting metrics for batch 65\n","\t\tGetting metrics for batch 66\n","\t\tGetting metrics for batch 67\n","\t\tGetting metrics for batch 68\n","\t\tGetting metrics for batch 69\n","\t\tGetting metrics for batch 70\n","\t\tGetting metrics for batch 71\n","\t\tGetting metrics for batch 72\n","\t\tGetting metrics for batch 73\n","\t\tGetting metrics for batch 74\n","\t\tGetting metrics for batch 75\n","\t\tGetting metrics for batch 76\n","\t\tGetting metrics for batch 77\n","\t\tGetting metrics for batch 78\n","\t\tGetting metrics for batch 79\n","\t\tGetting metrics for batch 80\n","\t\tGetting metrics for batch 81\n","\t\tGetting metrics for batch 82\n","\t\tGetting metrics for batch 83\n","\t\tGetting metrics for batch 84\n","\t\tGetting metrics for batch 85\n","\t\tGetting metrics for batch 86\n","\t\tGetting metrics for batch 87\n","\t\tGetting metrics for batch 88\n","\t\tGetting metrics for batch 89\n","\t\tGetting metrics for batch 90\n","\t\tGetting metrics for batch 91\n","\t\tGetting metrics for batch 92\n","\t\tGetting metrics for batch 93\n","\t\tGetting metrics for batch 94\n","\t\tGetting metrics for batch 95\n","\t\tGetting metrics for batch 96\n","\t\tGetting metrics for batch 97\n","\t\tGetting metrics for batch 98\n","\t\tGetting metrics for batch 99\n","\t\tGetting metrics for batch 100\n","\t\tGetting metrics for batch 101\n","\t\tGetting metrics for batch 102\n","\t\tGetting metrics for batch 103\n","\t\tGetting metrics for batch 104\n","\t\tGetting metrics for batch 105\n","\t\tGetting metrics for batch 106\n","\t\tGetting metrics for batch 107\n","\t\tGetting metrics for batch 108\n","\t\tGetting metrics for batch 109\n","\t\tGetting metrics for batch 110\n","\t\tGetting metrics for batch 111\n","\t\tGetting metrics for batch 112\n","\t\tGetting metrics for batch 113\n","\t\tGetting metrics for batch 114\n","\t\tGetting metrics for batch 115\n","\t\tGetting metrics for batch 116\n","\t\tGetting metrics for batch 117\n","\t\tGetting metrics for batch 118\n","\t\tGetting metrics for batch 119\n","\t\tGetting metrics for batch 120\n","\t\tGetting metrics for batch 121\n","\t\tGetting metrics for batch 122\n","\t\tGetting metrics for batch 123\n","\t\tGetting metrics for batch 124\n","\t\tGetting metrics for batch 125\n","\t\tGetting metrics for batch 126\n","\t\tGetting metrics for batch 127\n","\t\tGetting metrics for batch 128\n","\t\tGetting metrics for batch 129\n","\t\tGetting metrics for batch 130\n","\t\tGetting metrics for batch 131\n","\t\tGetting metrics for batch 132\n","\t\tGetting metrics for batch 133\n","\t\tGetting metrics for batch 134\n","\t\tGetting metrics for batch 135\n","\tSaved metrics of fold 2\n","\n","\n","\n","Saved all metrics\n","{0: {'mean': [0.0017505214494817397, 0.0017401266331766166, 0.0012795898259854784], 'std0': [0.0009916484355926513, 0.0009945955930971632, 0.0011367585144790948]}, 1: {'mean': [0.0017511330398858763, 0.0017420429809420716, 0.0012797125414306043], 'std0': [0.0009921796181622674, 0.0009950508089626537, 0.001136946444417916]}, 2: {'mean': [0.0017508658708310595, 0.0017422670242833156, 0.001278452662860646], 'std0': [0.0009884988560396083, 0.0009921478290183872, 0.0011345732445810356]}}\n"]}],"source":["print(\"Getting metrics for data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\n","print(all_folds_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"LeBlN4k7VZFY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running split 0 starting at 0 and ending with 8689\n","\tRunning Epoch 0\n","\t\tRunning through training dataset\n"]}],"source":["#model training on full dataset\n","exp = Experiment(exp_params['model']['name'], ftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuSnMkZmnDrG"},"outputs":[],"source":["# get best model\n","model = get_model(exp_params[\"model\"][\"name\"])\n","model = get_saved_model(model, '')\n","model_info = get_modelinfo('')\n","best_fold = model_info['results']['fold']\n","metric_path = os.path.join(config[\"root_dir\"], \"models/checkpoints/all_folds_metrics.json\")\n","all_folds_metrics = read_json(metric_path)\n","print('All folds metrics')\n","print(all_folds_metrics)\n","\n","print(\"\\nModel validation results\")\n","print(model_info['results']['trlosshistory'])\n","#visualization results\n","vis = Visualization(model_info, model_history)\n","vis.get_results()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvqYKcgPnm9r"},"outputs":[],"source":["'''\n","#model testing on small test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, smfte_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJFUzpYxF-1A"},"outputs":[],"source":["#model testing on test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, test_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}