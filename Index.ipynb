{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29263,"status":"ok","timestamp":1706170071488,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"zLCTeDm-jLfS","outputId":"a02e1ff4-0dc5-4bc6-e974-da18c179cf25"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1706170071901,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"AnaSX0XUjLfV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e67807a-2d57-4afc-c654-d3b6087fa4d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification\n","common\t\t    dataloading  index.py\t      project-structure.md  visualization\n","config.yaml\t    experiments  models\t\t      README.md\n","corrupt_files.json  Index_bc.py  preprocess\t      run.yaml\n","data\t\t    Index.ipynb  preprocess_input.py  transforms\n"]}],"source":["# move into project directory\n","repo_name = \"crop-damage-classification\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qVSyI39BjLfW","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1706170071901,"user_tz":300,"elapsed":24,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"e5bbc76c-691c-4592-f676-238292f8d002"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"markdown","metadata":{"id":"uZ3v5itpj3ae"},"source":["# Following cells are for downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1Ox_E5YpjLfW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706170088711,"user_tz":300,"elapsed":16827,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"14e6d626-167e-45e4-86d5-11339f2d083f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting boto3\n","  Downloading boto3-1.34.27-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.35.0,>=1.34.27 (from boto3)\n","  Downloading botocore-1.34.27-py3-none-any.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n","  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.27->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.27->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.27->boto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.34.27 botocore-1.34.27 jmespath-1.0.1 s3transfer-0.10.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# comment if not required\n","!pip install boto3\n","!pip install tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"kwOcWXgAjLfW","executionInfo":{"status":"ok","timestamp":1706170104461,"user_tz":300,"elapsed":15765,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from transforms.transforms import ToTensor, Resize, CenterCrop\n","from dataloading.dataset import CropDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_modelinfo, get_saved_model, read_json, insert_index_2csv, get_model_data\n","from models.resnet18 import Resnet18\n","from models.custom_models import get_model\n","from experiments.experiments import Experiment\n","from visualization.visualization import Visualization\n","from experiments.test_model import ModelTester\n","from preprocess.preprocessor import Preprocessor\n","from tqdm import tqdm\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"i_Jc81A_kF4o","executionInfo":{"status":"ok","timestamp":1706170104775,"user_tz":300,"elapsed":338,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["import boto3\n","from pathlib import Path\n","from botocore import UNSIGNED\n","from botocore.client import Config\n","from tqdm.notebook import tqdm\n","\n","def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n","    file_names = []\n","    folders = []\n","\n","    default_kwargs = {\n","        \"Bucket\": bucket_name,\n","        \"Prefix\": prefix\n","    }\n","    next_token = \"\"\n","\n","    while next_token is not None:\n","        updated_kwargs = default_kwargs.copy()\n","        if next_token != \"\":\n","            updated_kwargs[\"ContinuationToken\"] = next_token\n","\n","        response = s3_client.list_objects_v2(**updated_kwargs)\n","        contents = response.get(\"Contents\")\n","\n","        for result in contents:\n","            key = result.get(\"Key\")\n","            if key[-1] == \"/\":\n","                folders.append(key)\n","            else:\n","                file_names.append(key)\n","\n","        next_token = response.get(\"NextContinuationToken\")\n","\n","    return file_names, folders\n","\n","def download_files(s3_client, bucket_name, local_path, file_names, folders):\n","    local_path = Path(local_path)\n","\n","    for folder in tqdm(folders):\n","        folder_path = Path.joinpath(local_path, folder)\n","\t\t\t\t# Create all folders in the path\n","        folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for file_name in tqdm(file_names):\n","        file_path = Path.joinpath(local_path, file_name)\n","\t\t\t\t# Create folder for parent directory\n","        file_path.parent.mkdir(parents=True, exist_ok=True)\n","        s3_client.download_file(\n","            bucket_name,\n","            file_name,\n","            str(file_path)\n","        )\n","\n","data_path = 'data/input/images'\n","if not(os.path.exists(os.path.join(os.getcwd(), data_path))):\n","    client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n","    file_names, folders = get_file_folders(client, 'cgiar-crop-damage-classification-challenge')\n","    download_files(\n","        client,\n","        'cgiar-crop-damage-classification-challenge',\n","        \"/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input\",\n","        file_names,\n","        folders\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1706170105051,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"swtjFj_LjLfX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5ddd470-ee8d-4601-a282-84f5bc6d2665"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config parameters\n","\n","{'X_key': 'image', 'data_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data', 'device': 'cuda', 'img_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input/images', 'output_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification', 'use_gpu': True, 'y_key': 'label'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"I8-C7DyPZfie","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1706170105052,"user_tz":300,"elapsed":13,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"fc261073-7242-476d-c762-bf1f72b669ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfrom PIL import Image, UnidentifiedImageError\\nimport json\\nimport pandas as pd\\n\\nimage_files = os.listdir(os.path.join(config[\\'root_dir\\'],\\'data/input/images\\'))\\ncorrupt_files = []\\nprint(\\'scanning files for corrupt images\\n\\n\\')\\nfor img_file in tqdm(image_files):\\n    try:\\n        img = Image.open(os.path.join(config[\\'img_dir\\'], img_file))\\n    except UnidentifiedImageError as e:\\n        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\\n            os.remove(os.path.join(config[\"data_dir\"], img_file))\\n        corrupt_files.append(img_file)\\n#corrupt_files = [\\'c3092a5186771280a99200624c4f67e33fde95ca.jpg\\']\\ndata = { \"data\": corrupt_files }\\nwith open(\\'corrupt_files.json\\', \\'w\\') as fp:\\n    json.dump(data, fp)\\n\\ntrain_path = os.path.join(config[\\'data_dir\\'], \\'input/Train.csv\\')\\ntrain_df = pd.read_csv(train_path)\\nerror_rows = train_df.loc[train_df[\\'filename\\'].isin(corrupt_files)].index.tolist()\\ntrain_df = train_df.drop(labels = error_rows)\\ntrain_df.to_csv(train_path, index = False)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["#clean up invalid images\n","\n","'''\n","from PIL import Image, UnidentifiedImageError\n","import json\n","import pandas as pd\n","\n","image_files = os.listdir(os.path.join(config['root_dir'],'data/input/images'))\n","corrupt_files = []\n","print('scanning files for corrupt images\\n\\n')\n","for img_file in tqdm(image_files):\n","    try:\n","        img = Image.open(os.path.join(config['img_dir'], img_file))\n","    except UnidentifiedImageError as e:\n","        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\n","            os.remove(os.path.join(config[\"data_dir\"], img_file))\n","        corrupt_files.append(img_file)\n","#corrupt_files = ['c3092a5186771280a99200624c4f67e33fde95ca.jpg']\n","data = { \"data\": corrupt_files }\n","with open('corrupt_files.json', 'w') as fp:\n","    json.dump(data, fp)\n","\n","train_path = os.path.join(config['data_dir'], 'input/Train.csv')\n","train_df = pd.read_csv(train_path)\n","error_rows = train_df.loc[train_df['filename'].isin(corrupt_files)].index.tolist()\n","train_df = train_df.drop(labels = error_rows)\n","train_df.to_csv(train_path, index = False)\n","'''"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"GHtbUZ58jID3","executionInfo":{"status":"ok","timestamp":1706170105999,"user_tz":300,"elapsed":956,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["# insert index column to label csvs\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Train.csv'))\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Test.csv'))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1706170106389,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"b5bdgR1sjLfX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"745d7c94-ff3d-4632-a2cb-19dcf71c2501"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 350, 'crop_dim': 256}, 'train': {'shuffle_data': False, 'batch_size': 128, 'val_split_method': 'fixed-split', 'k': 3, 'val_percentage': 20, 'loss': 'cross-entropy', 'epoch_interval': 1, 'num_epochs': 30}, 'model': {'name': 'alexnet', 'optimizer': 'Adam', 'lr': 0.001, 'weight_decay': 1e-05, 'amsgrad': False, 'momentum': 0.9}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"GEnkN2-_jLfY","executionInfo":{"status":"ok","timestamp":1706170106390,"user_tz":300,"elapsed":21,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qS5oBZb9jLfY","executionInfo":{"status":"ok","timestamp":1706170106390,"user_tz":300,"elapsed":20,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["#preprocess data or load preprocessed data\n","\n","#build label dict\n","label_dict = {\n","    'DR': 0,\n","    'G': 1,\n","    'ND': 2,\n","    'WD': 3,\n","    'other': 4\n","}\n","\n","class_dict = {\n","    0: 'DR',\n","    1: 'G',\n","    2: 'ND',\n","    3: 'WD',\n","    4: 'other'\n","}"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1706170106391,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":300},"id":"Gu_4BlM-UCkr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a505c183-a328-4320-c3fa-0ef568f76903"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full train dataset length: 26068\n","Test dataset length: 8663\n","Subset train dataset length: 260\n","Subset test dataset length: 86 \n","\n"]}],"source":["#save X_key and y_key\n","save2config('X_key', 'image')\n","save2config('y_key', 'label')\n","\n","#transform data\n","data_transforms = [ToTensor(), Resize(exp_params['transform']['resize_dim']), CenterCrop(exp_params['transform']['crop_dim'])]\n","\n","#convert to dataset\n","ftr_dataset = CropDataset('input/Train.csv', label_dict, False)\n","test_dataset = CropDataset('input/Test.csv', label_dict, True)\n","smlen = int(0.01 * len(ftr_dataset))\n","smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","smtelen = int(0.01 * len(test_dataset))\n","smfte_dataset = torch.utils.data.Subset(test_dataset, list(range(smtelen)))\n","print('Full train dataset length:', len(ftr_dataset))\n","print('Test dataset length:', len(test_dataset))\n","print('Subset train dataset length:', smlen)\n","print('Subset test dataset length:', smtelen, '\\n')\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9oYnMlWAtKHc","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1706170106393,"user_tz":300,"elapsed":17,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"1a6a37b1-253e-4bf2-e856-3f49b1d239fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"Getting metrics for small data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["'''\n","print(\"Getting metrics for small data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"i-YdanntUCks","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1706170106661,"user_tz":300,"elapsed":281,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"98afbfaa-d72e-478e-ddef-141e78623b5c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n#running experiment on small subset of the dataset\\nall_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\\nall_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\\nprint(all_folds_metrics)\\nprint('\\n\\n')\\n\\nexp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\\nmodel_history = exp.train()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["'''\n","#running experiment on small subset of the dataset\n","all_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\n","all_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\n","print(all_folds_metrics)\n","print('\\n\\n')\n","\n","exp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()\n","'''"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"NKroKRypQgkc","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1706170106662,"user_tz":300,"elapsed":18,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"07f3c47d-2ad6-4c69-a70b-4c386980edba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"Getting metrics for data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["'''\n","print(\"Getting metrics for data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","source":["print(len(os.listdir(\"data/input/images\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhRFX6--ozI6","executionInfo":{"status":"ok","timestamp":1706170333929,"user_tz":300,"elapsed":11003,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"8b6f4b29-af9a-432e-e812-88265b8ade3d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["34731\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeBlN4k7VZFY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9037b42f-1ef9-42ba-fc08-3dcfc3d1807e"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: {'mean': [0.0017170946972042906, 0.0017039978036693499, 0.0012039661407470704], 'std0': [0.0009368337836920046, 0.0009318411934609507, 0.00105056552325978]}}\n","\n","\n","\n","Loading saved model\n","{'valloss': 1.0346454503255866, 'valacc': tensor(0.5538, device='cuda:0'), 'trloss': 0.937634002199221, 'trlosshistory': tensor([20.1547,  1.0772,  1.0758,  1.0615,  1.0148,  1.0135,  0.9967,  1.0167,\n","         0.9963,  0.9410,  0.9334,  0.9245,  0.8942,  0.7905,  0.8511,  0.9807,\n","         0.9762,  0.8027,  0.7869,  0.8847,  0.9376], device='cuda:0'), 'vallosshistory': tensor([1.1115, 1.0834, 1.0692, 1.0583, 1.0559, 1.0547, 1.0714, 1.0220, 1.0281,\n","        1.0474, 1.0441, 1.0728, 1.0525, 1.0892, 1.0570, 1.0288, 1.0326, 1.0527,\n","        1.0748, 1.0541, 1.0346], device='cuda:0'), 'valacchistory': tensor([0.4389, 0.4623, 0.4853, 0.5116, 0.5170, 0.5154, 0.5122, 0.5425, 0.5367,\n","        0.5281, 0.5348, 0.5220, 0.5216, 0.4957, 0.5423, 0.5538, 0.5446, 0.5459,\n","        0.5314, 0.5279, 0.5538], device='cuda:0'), 'fold': -1, 'epoch': 20}\n","\n","\n","\n","Running straight split\n","\tRunning Epoch 21\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 163/163 [1:40:22<00:00, 36.95s/it]\n","\t\tRunning through validation set: 100%|██████████| 41/41 [24:21<00:00, 35.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 21 Training Loss: 0.7697225456213785\n","\tEpoch 21 Validation Loss: 1.2312208510122074\n","\tEpoch 21 Validation Accuracy: 0.4845578372478485\n","\n","\tRunning Epoch 22\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 163/163 [16:07<00:00,  5.94s/it]\n","\t\tRunning through validation set: 100%|██████████| 41/41 [03:52<00:00,  5.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 22 Training Loss: 0.7413023334388623\n","\tEpoch 22 Validation Loss: 1.0802346786747459\n","\tEpoch 22 Validation Accuracy: 0.5317475199699402\n","\n","\tRunning Epoch 23\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 163/163 [15:41<00:00,  5.78s/it]\n","\t\tRunning through validation set: 100%|██████████| 41/41 [03:57<00:00,  5.80s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 23 Training Loss: 0.8116212773197304\n","\tEpoch 23 Validation Loss: 1.058360504973719\n","\tEpoch 23 Validation Accuracy: 0.5447918772697449\n","\n","\tRunning Epoch 24\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 163/163 [15:54<00:00,  5.86s/it]\n","\t\tRunning through validation set: 100%|██████████| 41/41 [03:49<00:00,  5.61s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 24 Training Loss: 0.8865652015785953\n","\tEpoch 24 Validation Loss: 1.054313574725919\n","\tEpoch 24 Validation Accuracy: 0.5463264584541321\n","\n","\tRunning Epoch 25\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 163/163 [15:57<00:00,  5.87s/it]\n","\t\tRunning through validation set: 100%|██████████| 41/41 [03:52<00:00,  5.68s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 25 Training Loss: 0.9355958327918966\n","\tEpoch 25 Validation Loss: 1.0388463497642086\n","\tEpoch 25 Validation Accuracy: 0.5497794151306152\n","\n","\tRunning Epoch 26\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set:  64%|██████▍   | 104/163 [10:04<06:26,  6.55s/it]"]}],"source":["#model training on full dataset\n","all_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\n","all_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\n","print(all_folds_metrics)\n","print('\\n\\n')\n","\n","exp = Experiment(exp_params['model']['name'], ftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuSnMkZmnDrG","executionInfo":{"status":"aborted","timestamp":1706170226711,"user_tz":300,"elapsed":15,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["# get best model\n","model = get_model(exp_params[\"model\"][\"name\"])\n","model = get_saved_model(model, '')\n","model_info = get_modelinfo('')\n","_, model_history, _ = get_model_data('')\n","best_fold = model_info['results']['fold']\n","metric_path = os.path.join(config[\"root_dir\"], \"models/checkpoints/all_folds_metrics.json\")\n","all_folds_metrics = read_json(metric_path)\n","print('All folds metrics')\n","print(all_folds_metrics)\n","\n","print(\"\\nModel validation results\")\n","print(model_info['results']['trlosshistory'])\n","#visualization results\n","vis = Visualization(model_info, model_history)\n","vis.get_results()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvqYKcgPnm9r","executionInfo":{"status":"aborted","timestamp":1706170226711,"user_tz":300,"elapsed":15,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["'''\n","#model testing on small test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}']\n","mt = ModelTester(model, smfte_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJFUzpYxF-1A","executionInfo":{"status":"aborted","timestamp":1706170226711,"user_tz":300,"elapsed":15,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["#model testing on test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}']\n","mt = ModelTester(model, test_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}