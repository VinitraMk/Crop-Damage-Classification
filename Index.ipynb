{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4229,"status":"ok","timestamp":1705700102110,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":300},"id":"zLCTeDm-jLfS","outputId":"20d2ca4a-caa3-4716-c991-b1c437b86132"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1705700102111,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":300},"id":"AnaSX0XUjLfV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fe98aa7-2ba1-4ec8-c38a-c384446f6ee3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Personal-Projects/crop-damage-classification\n","common\t\t    data\t Index_bc.py  models\t  preprocess_input.py\trun.yaml\n","config.yaml\t    dataloading  Index.ipynb  output\t  project-structure.md\ttransforms\n","corrupt_files.json  experiments  index.py     preprocess  README.md\t\tvisualization\n"]}],"source":["# move into project directory\n","repo_name = \"crop-damage-classification\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qVSyI39BjLfW","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1705700102111,"user_tz":300,"elapsed":9,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"31d6f1d5-5dcc-4d86-b544-1a8f25c2d5ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"markdown","metadata":{"id":"uZ3v5itpj3ae"},"source":["# Following cells are for downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1Ox_E5YpjLfW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705700133865,"user_tz":300,"elapsed":31761,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"914fd92b-599e-4a10-adec-00634a792dae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.23)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.23 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.23)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.23->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.23->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.23->boto3) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# comment if not required\n","!pip install boto3\n","!pip install tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"kwOcWXgAjLfW","executionInfo":{"status":"ok","timestamp":1705700141233,"user_tz":300,"elapsed":7386,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from transforms.transforms import ToTensor, Resize, CenterCrop\n","from dataloading.dataset import CropDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_modelinfo, get_saved_model, read_json, insert_index_2csv\n","from models.resnet18 import Resnet18\n","from models.custom_models import get_model\n","from experiments.experiments import Experiment\n","from visualization.visualization import Visualization\n","from experiments.test_model import ModelTester\n","from preprocess.preprocessor import Preprocessor\n","from tqdm import tqdm\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"i_Jc81A_kF4o","executionInfo":{"status":"ok","timestamp":1705700141233,"user_tz":300,"elapsed":14,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["import boto3\n","from pathlib import Path\n","from botocore import UNSIGNED\n","from botocore.client import Config\n","from tqdm.notebook import tqdm\n","\n","def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n","    file_names = []\n","    folders = []\n","\n","    default_kwargs = {\n","        \"Bucket\": bucket_name,\n","        \"Prefix\": prefix\n","    }\n","    next_token = \"\"\n","\n","    while next_token is not None:\n","        updated_kwargs = default_kwargs.copy()\n","        if next_token != \"\":\n","            updated_kwargs[\"ContinuationToken\"] = next_token\n","\n","        response = s3_client.list_objects_v2(**updated_kwargs)\n","        contents = response.get(\"Contents\")\n","\n","        for result in contents:\n","            key = result.get(\"Key\")\n","            if key[-1] == \"/\":\n","                folders.append(key)\n","            else:\n","                file_names.append(key)\n","\n","        next_token = response.get(\"NextContinuationToken\")\n","\n","    return file_names, folders\n","\n","def download_files(s3_client, bucket_name, local_path, file_names, folders):\n","    local_path = Path(local_path)\n","\n","    for folder in tqdm(folders):\n","        folder_path = Path.joinpath(local_path, folder)\n","\t\t\t\t# Create all folders in the path\n","        folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for file_name in tqdm(file_names):\n","        file_path = Path.joinpath(local_path, file_name)\n","\t\t\t\t# Create folder for parent directory\n","        file_path.parent.mkdir(parents=True, exist_ok=True)\n","        s3_client.download_file(\n","            bucket_name,\n","            file_name,\n","            str(file_path)\n","        )\n","\n","data_path = 'data/input/images'\n","if not(os.path.exists(os.path.join(os.getcwd(), data_path))):\n","    client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n","    file_names, folders = get_file_folders(client, 'cgiar-crop-damage-classification-challenge')\n","    download_files(\n","        client,\n","        'cgiar-crop-damage-classification-challenge',\n","        \"/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input\",\n","        file_names,\n","        folders\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":766,"status":"ok","timestamp":1705700141987,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":300},"id":"swtjFj_LjLfX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0df5d07a-5e97-440f-ba34-66f0dac279c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config parameters\n","\n","{'X_key': 'image', 'data_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data', 'device': 'cpu', 'img_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/data/input/images', 'output_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/crop-damage-classification', 'use_gpu': False, 'y_key': 'label'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"I8-C7DyPZfie","colab":{"base_uri":"https://localhost:8080/","height":192},"executionInfo":{"status":"ok","timestamp":1705700141988,"user_tz":300,"elapsed":33,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"d469347e-761d-44ae-81c1-95e2957e0d53"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfrom PIL import Image, UnidentifiedImageError\\nimport json\\nimport pandas as pd\\n\\nimage_files = os.listdir(os.path.join(config[\\'root_dir\\'],\\'data/input/images\\'))\\ncorrupt_files = []\\nprint(\\'scanning files for corrupt images\\n\\n\\')\\nfor img_file in tqdm(image_files):\\n    try:\\n        img = Image.open(os.path.join(config[\\'img_dir\\'], img_file))\\n    except UnidentifiedImageError as e:\\n        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\\n            os.remove(os.path.join(config[\"data_dir\"], img_file))\\n        corrupt_files.append(img_file)\\n#corrupt_files = [\\'c3092a5186771280a99200624c4f67e33fde95ca.jpg\\']\\ndata = { \"data\": corrupt_files }\\nwith open(\\'corrupt_files.json\\', \\'w\\') as fp:\\n    json.dump(data, fp)\\n\\ntrain_path = os.path.join(config[\\'data_dir\\'], \\'input/Train.csv\\')\\ntrain_df = pd.read_csv(train_path)\\nerror_rows = train_df.loc[train_df[\\'filename\\'].isin(corrupt_files)].index.tolist()\\ntrain_df = train_df.drop(labels = error_rows)\\ntrain_df.to_csv(train_path, index = False)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["#clean up invalid images\n","\n","'''\n","from PIL import Image, UnidentifiedImageError\n","import json\n","import pandas as pd\n","\n","image_files = os.listdir(os.path.join(config['root_dir'],'data/input/images'))\n","corrupt_files = []\n","print('scanning files for corrupt images\\n\\n')\n","for img_file in tqdm(image_files):\n","    try:\n","        img = Image.open(os.path.join(config['img_dir'], img_file))\n","    except UnidentifiedImageError as e:\n","        if os.path.exists(os.path.join(config[\"data_dir\"], img_file)):\n","            os.remove(os.path.join(config[\"data_dir\"], img_file))\n","        corrupt_files.append(img_file)\n","#corrupt_files = ['c3092a5186771280a99200624c4f67e33fde95ca.jpg']\n","data = { \"data\": corrupt_files }\n","with open('corrupt_files.json', 'w') as fp:\n","    json.dump(data, fp)\n","\n","train_path = os.path.join(config['data_dir'], 'input/Train.csv')\n","train_df = pd.read_csv(train_path)\n","error_rows = train_df.loc[train_df['filename'].isin(corrupt_files)].index.tolist()\n","train_df = train_df.drop(labels = error_rows)\n","train_df.to_csv(train_path, index = False)\n","'''"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"GHtbUZ58jID3","executionInfo":{"status":"ok","timestamp":1705700141988,"user_tz":300,"elapsed":31,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# insert index column to label csvs\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Train.csv'))\n","insert_index_2csv(os.path.join(config['data_dir'], 'input/Test.csv'))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1705700141988,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":300},"id":"b5bdgR1sjLfX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9630cea8-dcf5-48c3-b82a-56b1d309de89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 350, 'crop_dim': 256}, 'train': {'shuffle_data': False, 'batch_size': 128, 'val_split_method': 'k-fold', 'k': 3, 'val_percentage': 20, 'loss': 'cross-entropy', 'epoch_interval': 1, 'num_epochs': 2}, 'model': {'name': 'alexnet', 'optimizer': 'Adam', 'lr': 0.001, 'weight_decay': 1e-05, 'amsgrad': False, 'momentum': 0.9}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"GEnkN2-_jLfY","executionInfo":{"status":"ok","timestamp":1705700141989,"user_tz":300,"elapsed":27,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qS5oBZb9jLfY","executionInfo":{"status":"ok","timestamp":1705700141989,"user_tz":300,"elapsed":27,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["#preprocess data or load preprocessed data\n","\n","#build label dict\n","label_dict = {\n","    'DR': 0,\n","    'G': 1,\n","    'ND': 2,\n","    'WD': 3,\n","    'other': 4\n","}\n","\n","class_dict = {\n","    0: 'DR',\n","    1: 'G',\n","    2: 'ND',\n","    3: 'WD',\n","    4: 'other'\n","}"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1705700141990,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":300},"id":"Gu_4BlM-UCkr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3746ec58-0323-4187-e0d3-bed0e66b91ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full train dataset length: 26068\n","Test dataset length: 8663\n","Subset train dataset length: 260\n","Subset test dataset length: 86 \n","\n"]}],"source":["#save X_key and y_key\n","save2config('X_key', 'image')\n","save2config('y_key', 'label')\n","\n","#transform data\n","data_transforms = [ToTensor(), Resize(exp_params['transform']['resize_dim']), CenterCrop(exp_params['transform']['crop_dim'])]\n","\n","#convert to dataset\n","ftr_dataset = CropDataset('input/Train.csv', label_dict, False)\n","test_dataset = CropDataset('input/Test.csv', label_dict, True)\n","smlen = int(0.01 * len(ftr_dataset))\n","smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","smtelen = int(0.01 * len(test_dataset))\n","smfte_dataset = torch.utils.data.Subset(test_dataset, list(range(smtelen)))\n","print('Full train dataset length:', len(ftr_dataset))\n","print('Test dataset length:', len(test_dataset))\n","print('Subset train dataset length:', smlen)\n","print('Subset test dataset length:', smtelen, '\\n')\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9oYnMlWAtKHc","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1705700141991,"user_tz":300,"elapsed":24,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"117c9e06-a1e5-4a58-b82a-fd0e4e412885"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"Getting metrics for small data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["'''\n","print(\"Getting metrics for small data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(smftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"i-YdanntUCks","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1705700141991,"user_tz":300,"elapsed":23,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"5c312911-bbe5-4e28-999b-e2cf34e21a97"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n#running experiment on small subset of the dataset\\nall_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\\nall_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\\nexp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\\nmodel_history = exp.train()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["'''\n","#running experiment on small subset of the dataset\n","all_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\n","all_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\n","exp = Experiment(exp_params['model']['name'], smftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()\n","'''"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"NKroKRypQgkc","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1705700141991,"user_tz":300,"elapsed":21,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"e7d49fc5-e6d8-40eb-f9e0-5336b22caf2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"Getting metrics for data\")\\npreop = Preprocessor()\\nall_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\\nprint(all_folds_metrics)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["'''\n","print(\"Getting metrics for data\")\n","preop = Preprocessor()\n","all_folds_metrics = preop.get_dataset_metrics(ftr_dataset, data_transforms)\n","print(all_folds_metrics)\n","'''"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"LeBlN4k7VZFY","colab":{"base_uri":"https://localhost:8080/","height":566},"outputId":"e9666860-9b99-42f1-8bfb-2e18e84b6a73","executionInfo":{"status":"error","timestamp":1705700711308,"user_tz":300,"elapsed":569337,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: {'mean': [0.0017509627575967826, 0.001740593769971062, 0.001279151205923043], 'std0': [0.0009911220447689879, 0.0009941544018539728, 0.0011366211900524065]}, 1: {'mean': [0.001751121586444331, 0.0017421398677077947, 0.0012799400909274232], 'std0': [0.0009921487639932072, 0.0009948029237634996, 0.001136322816212972]}, 2: {'mean': [0.0017505734574561026, 0.0017417813048643223, 0.0012787652950660856], 'std0': [0.0009890975905399696, 0.0009928238158132515, 0.0011353534810683308]}, 3: {'mean': [0.0017509331890180999, 0.0017415279266881007, 0.0012793144759009865], 'std0': [0.0009907820645500632, 0.0009939293066660562, 0.0011360991234872855]}}\n","\n","\n","\n","None\n","\n","\n","\n","Running split 0 starting at 0 and ending with 8689\n","\tRunning Epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set:   4%|â–Ž         | 5/136 [09:24<4:06:34, 112.94s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-f9c25c6240d8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftr_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_folds_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/Personal-Projects/crop-damage-classification/experiments/experiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_type)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         trlosshistory, vallosshistory, valacchistory)\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     model, model_info = self.__conduct_training(model, vi, si, epoch_index,\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         trlosshistory, vallosshistory, valacchistory)\n","\u001b[0;32m/content/drive/MyDrive/Personal-Projects/crop-damage-classification/experiments/experiments.py\u001b[0m in \u001b[0;36m__conduct_training\u001b[0;34m(self, model, fold_idx, fold_si, epoch_index, train_loader, val_loader, train_len, val_len, trlosshistory, vallosshistory, valacchistory)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m#print(f'\\t\\tRunning through training dataset')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t\\tRunning through training set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mimg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Personal-Projects/crop-damage-classification/dataloading/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimg_tensor_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#img = io.imread(img_tensor_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname2numlblmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'damage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0midint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#model training on full dataset\n","all_folds_metrics = read_json(os.path.join(config['root_dir'], 'models/checkpoints/all_folds_metrics.json'))\n","all_folds_metrics = {int(k): v for k,v in all_folds_metrics.items()}\n","print(all_folds_metrics)\n","print('\\n\\n')\n","\n","exp = Experiment(exp_params['model']['name'], ftr_dataset, data_transforms, all_folds_metrics)\n","model_history = exp.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuSnMkZmnDrG","executionInfo":{"status":"aborted","timestamp":1705700710937,"user_tz":300,"elapsed":613574,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# get best model\n","model = get_model(exp_params[\"model\"][\"name\"])\n","model = get_saved_model(model, '')\n","model_info = get_modelinfo('')\n","best_fold = model_info['results']['fold']\n","metric_path = os.path.join(config[\"root_dir\"], \"models/checkpoints/all_folds_metrics.json\")\n","all_folds_metrics = read_json(metric_path)\n","print('All folds metrics')\n","print(all_folds_metrics)\n","\n","print(\"\\nModel validation results\")\n","print(model_info['results']['trlosshistory'])\n","#visualization results\n","vis = Visualization(model_info, model_history)\n","vis.get_results()"]},{"cell_type":"code","source":["from common.utils import get_exp_params, get_accuracy, get_config, get_model_filename, save_experiment_output, image_collate\n","from torch.utils.data import DataLoader, Subset\n","import torch\n","from matplotlib import pyplot as plt\n","import os\n","import pandas as pd\n","import torch.nn.functional as F\n","from torchvision.transforms import Normalize, Compose\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","\n","class ModelTester:\n","\n","    def __init__(self, model, te_dataset, data_transforms, metrics):\n","        cfg = get_config()\n","        self.te_dataset = te_dataset\n","        self.model = model.cpu()\n","        self.model.eval()\n","        self.exp_params = get_exp_params()\n","        self.te_loader = DataLoader(self.te_dataset,\n","            batch_size = self.exp_params['train']['batch_size'],\n","            shuffle = False\n","        )\n","        self.output_dir = cfg['output_dir']\n","        self.device = cfg['device']\n","        self.metrics = metrics\n","        self.data_transforms = data_transforms\n","        self.test_df = pd.read_csv(os.path.join(cfg['data_dir'], 'input/Test.csv'))\n","\n","    def __plot_results(self, predicted_labels, subset_len = 10):\n","        fr = list(range(subset_len))\n","        subset_dataset = Subset(self.te_dataset, fr)\n","        subset_loader = DataLoader(subset_dataset, batch_size = 1, shuffle = False)\n","        fl = len(subset_dataset)\n","        plt.clf()\n","        plt.figure(figsize = (subset_len, 1))\n","        for bi, batch in enumerate(subset_loader):\n","            img = batch[self.X_key][0]\n","            plt.subplot(1,10,bi+1).set_title(predicted_labels[bi])\n","            plt.imshow(batch[bi,:,:,:])\n","            plt.axis(False)\n","        plt.show()\n","        plt.savefig(os.path.join(self.output_dir, \"sample_test_results.png\"))\n","\n","    def test_and_save_csv(self, lbl_dict, plot_sample_results = False):\n","        warnings.filterwarnings('ignore')\n","        self.model = self.model.to(self.device)\n","        test_loader = DataLoader(self.te_dataset,\n","            batch_size = self.exp_params[\"train\"][\"batch_size\"], shuffle = False,\n","            collate_fn = image_collate)\n","        self.model.eval()\n","        running_loss = 0.0\n","        acc = 0.0\n","        num2class = lambda x: lbl_dict[x.item()]\n","        sub_lbls = ['ID', 'DR', 'G', 'ND', 'WD', 'other']\n","        rpath = os.path.join(self.output_dir, \"results.csv\")\n","        cbi = 0\n","        bsize = self.exp_params['train']['batch_size']\n","        if os.path.exists(rpath):\n","            results_df = pd.read_csv(rpath)\n","            no_rows = len(results_df)\n","            if no_rows % bsize == 0:\n","                cbi = (no_rows // bsize) - 1\n","                cbin = cbi * bsize\n","            else:\n","                cbi = no_rows // bsize\n","                cbin = cbi * bsize\n","            cbir = list(range(cbin, no_rows))\n","            results_df = results_df.drop(labels = cbir, axis = 0)\n","        else:\n","            results_df = pd.DataFrame([], columns = sub_lbls)\n","            cbi = 0\n","\n","        data_transforms = Compose(self.data_transforms)\n","        normalize = Normalize(self.metrics['mean'], self.metrics['std0'])\n","        with torch.no_grad():\n","            for bi, batch in enumerate(tqdm(test_loader, desc = 'Running through test dataset: ', position = 0, leave = True)):\n","                if bi >= cbi:\n","                    img_batch = list(map(data_transforms, batch[1]))\n","                    img_batch = np.stack(img_batch, 0)\n","                    img_batch = normalize(torch.from_numpy(img_batch)).to(self.device)\n","                    #img_target = torch.from_numpy(batch[2]).to(self.device)\n","                    img_ids = self.test_df.loc[batch[0],'ID'].tolist()\n","                    op = self.model(normalize(img_batch))\n","                    print(op.size())\n","                    opprobs = F.softmax(op, dim = 1)\n","                    print(opprobs.size())\n","                    print(op[0], opprobs[0])\n","                    oplbls = torch.argmax(op, 1)\n","                    classlbls = list(map(num2class, oplbls))\n","                    res = [[id] + preds for id,preds in zip(img_ids, op.tolist())]\n","                    batch_df = pd.DataFrame(res, columns = sub_lbls)\n","                    results_df = pd.concat([results_df, batch_df], 0)\n","                    results_df.to_csv(rpath, index = False)\n","                    del batch\n","                else:\n","                    pass\n",""],"metadata":{"id":"2fy9ppDNGzS3","executionInfo":{"status":"aborted","timestamp":1705700711310,"user_tz":300,"elapsed":15,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvqYKcgPnm9r","executionInfo":{"status":"aborted","timestamp":1705700711310,"user_tz":300,"elapsed":15,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["#model testing on small test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, smfte_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJFUzpYxF-1A","executionInfo":{"status":"aborted","timestamp":1705700711311,"user_tz":300,"elapsed":15,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["#model testing on test dataset\n","print(\"\\n\\nTesting Saved Model\")\n","metrics = all_folds_metrics[f'{best_fold}'] if exp_params['train']['val_split_method'] == 'k-fold' else all_folds_metrics\n","mt = ModelTester(model, test_dataset, data_transforms, metrics)\n","mt.test_and_save_csv(class_dict)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}